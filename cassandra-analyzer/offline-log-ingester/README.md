# Ingest Tarball of logs into Kibana
## What is "offline log analysis"?
Sometimes it is preferable to do "online log analysis", which is where you collect logs on a live cluster and ingest into Elasticsearch/Kibana (or some other dashboard). However, there are situations where this is not possible or preferable and you want to grab some logs, put them in a tarball, and ingest into your dashboard, often running in a separate host. We call this "offline log analysis". 

After you collect your logs and grab other diagnostic data, you need to ingest it into your Dashboard. This is what this tool is for. Specifically, we ingest into Elasticsearch and Kibana using Filebeat.

## Setup
- Requires python3 and pip3
- `pip3 install -r requirements.txt`
- Place a log tarball in `./log-tarballs-to-ingest/` (currently not automating, you have to do this)
    * Make sure that this is the tarball either generated by our `collect_logs.py` script or by Opscenter. If this is a .zip, the script will unarchive the archive still but will likely fail unless the directory layout is exactly what DSE opsecenter returns. 
    * Having a directory like this gives us modularity and makes it easy to change. We can manually do this (`mv my.tgz ./log-tarballs-to-ingest/`) for now, and easily later add a script that does this for us, or even expose a web GUI for uploading it in. Then whatever we do, we place these tars in this directory

- Make sure ES and Kibana are running already (we will start filebeat later)
- Run a script, passing in certain metadata about the tarball. E.g., 
    ```
    python3 ingest_tarball.py my-client-logs-tarball.tar.gz my_client
    ```

    Or, if you want to clear out your filebeat indices first and filebeat registry:
    ```
    python3 ingest_tarball.py my-client-logs-tarball.tar.gz my_client --clean-out-filebeat-first
    ```
### Specifying Kibana endpoint
By default the script is pointing towards a kibana instance running on localhost. To specify a different kibana host, use the `--custom-config arg`:
    To pass in arbitrary config for the filebeat.yml file, send in a key (can be nested) and a value, e.g., 
    ```
    --custom-config setup.kibana.host 123.456.345.123:5601
    ```

### Other options
    1) You can also use `debug_mode` which doesn't write any logs to ES, only outputs to console by using the `--debug-mode` flag:
    ```
    python3 ingest_tarball.py my-client-logs-tarball.tar.gz my_client --debug-mode
    ```

    2) To pass in arbitrary config for the filebeat.yml file, use the `--custom-config` flag  send in a key (can be nested) and a value, e.g., 
    ```
    --custom-config setup.kibana.host 123.456.345.123:5601
    ```

    3) To cleanup all generated files if the script run successfully, pass in:
    ```
    --cleanup-on-finish
    ```

    4) ignore zeros in tarball (for when using a combined tarball; see [here](https://www.gnu.org/software/tar/manual/html_node/Ignore-Zeros.html) for what we do)
    ```
    --ignore-zeros 
    ```
    NOTE currently only works with gzipped tarballs (ie file extension tar.gz)

## What does the script do?
  - unzip the tarball
  - Put the logs in the folder we want it in
  - Generate a filebeat.yml for this (will be v0.2; v0.1 just write this ourselves)
  - start filebeat for one-off batch job that ingests these files into ELK 
      * Perhaps later we will just have filebeat running continually on our server, watching  whatever gets placed in

## Want to add some logs and run script again with the same config?
1) Add log files to the directory where similar logs are located: 
  `{self.base_filepath_for_logs}/<hostname>/<type>`.

  e.g., `{self.base_filepath_for_logs}/{example_hostname}/spark/worker/worker.log` 

2) Run filebeat again:

Replace the client_name and incident_id below and run it again
```
sudo filebeat -e -d "*" --c cassandra.vision/cassandra-analyzer/offline-log-ingester/logs-for-client/{client_name}/incident-{incident_id}/tmp/filebeat.yaml
```

- filebeat.yaml will be at: cassandra.vision/cassandra-analyzer/offline-log-ingester/logs-for-client/{client_name}/incident-{incident_id}/tmp/filebeat.yml
- Alternatively, if filebeat is still running (and is using the filebeat.yaml created by this script), you can just add the separate log files and it will find and ingest them. 

## Debugging
### Debugging the filebeat generator
  - Try editing the filebeat.yml manually and running again 
      See [instructions here](#want-to-add-some-logs-and-run-script-again-with-the-same-config) for running again and for where the generated filebeat.yaml is.

### Debugging ES
#### Try sudo filebeat setup
Sometimes filebeat will process logs correctly (which you will be able to see in the filebeat log output, since it will show a log (level DEBUG) for event "Publish event"that shows all the fields. However, it won't get into kibana correctly. Sometimes all it takes is running `sudo filebeat setup` so that filebeat configures for the current elasticsearch setup

Note that by default, `sudo filebeat setup` will use your default filebeat.yml file, which is found at `/etc/filebeat/filebeat.yml`. Make sure those settings are correct, since even running filebeat with a different filebeat.yml will not override some of these configs (especially configs under the `setup` property, e.g., `setup.template.settings`). Those settings only get set when running `filebeat setup`. 

If you want to setup filebeat using a different filebeat.yml file, you can use the `--c` flag, e.g.,:

```
sudo filebeat setup --c cassandra.vision/cassandra-analyzer/offline-log-ingester/logs-for-client/{client_name}/incident-{incident_id}/tmp/filebeat.yaml
```

#### Error: ConnectionError(('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')))
Your elasticsearch or kibana hosts might need to be set if you get an error that looks like the following after running the script:
```
elasticsearch.exceptions.ConnectionError: ConnectionError(('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))) caused by: ProtocolError(('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')))
```

You can find instructions for doing that above under [Specifying Kibana endpoint](#Specifying Kibana endpoint).

## Testing
### Current way to test: 
Run collect_logs test first. Then run ingest_tarball.py on that test tarball:

```
# if you haven't ran log collection test already...
cd cassandra-analyzer/offline-log-collector
pip3 install -r requirements.txt
pip3 install -r test/requirements.txt
cd test
python3 collect_logs_test.py

# now you have a test tarball to ingest in `offline-log-ingester/log-tarballs-to-ingest`
cd ../../offline-log-ingester
python3 ingest_tarball.py  test_client.tar.gz test_client 
# Or, if you are safe to wipe out filebeat registry and filebeat indices before running the test:
# python3 ingest_tarball.py  test_client.tar.gz test_client --clean-out-filebeat-first

```

### OLD WAY: use the test class
NOTE Currently out of date. 
Would do:
```
  pip3 install -r requirements.txt
  pip3 install -r test/requirements.txt
  cd test
  python3 ingest_tarball_test.py
```

Will need to update `ingest_tarball_test.py` for this to work though.


## Development
### Adding more logs to our tarball
If you want to add more logs from the Cassandra node into the tarball for ingestion:

1) Add another command to `NodeAnalyzer/nodetool.receive.v2.sh` 
  - `collect_logs.py` calls `NodeAnalyzer/nodetool.receive.v2.sh` on each node to get logs and conf files and nodetool output. So to add more files to that list, edit `NodeAnalyzer/nodetool.receive.v2.sh`.
  - Make sure to make a directory for it too e.g., something like:
      ```
      mkdir -p $data_dest_path/<your new path>
      ```

2) If `nodetool.receive.v2.sh` doesn't place the files into a directory that already gets copied, you will have to edit `helper_classes/node.py`
  - `collect_logs.py` will call `helper_classes/node.py` when it is creating the tarball.
  - See `helper_classes/node.py#copy_files_to_final_destination`, which copies all the files for a given node and creates directories in the destination directory if necessary.
  - The files you want copied need to be copied in the `node.py#copy_files_to_final_destination` method, or they will not end up in the tarball at the end.

3) Edit `ingest_tarball.py` to ingest these new files that you want added into Kibana
  - If these are log files that you are adding, Kibana won't see them unless you configure our ingestion tool to do so.
  - `ingest_tarball.py` actually looks at `helper_classes/filebeat_yml.py#log_type_definitions` for what will end up in your filebeat.yml, as well as for what to ingest into kibana. Add a new item in that list in order to ingest your new logs.
      * key (e.g., "spark.master") can be anything as long as it's unique, it is more of a label for us really.
      * `path_to_logs_source` is where the log collection needs to put these logs (corresponds to what you set in `node.py#copy_files_to_final_destination`). These do not need to be unique: e.g., `cassandra.dse-collectd` and `cassandra.garbage_collection` have the same `path_to_logs_source`, and it's no problem. It just means our script will try to copy all these logs twice, which doesn't hurt anything, but it will have two separate entries in our generated filebeat.yml with different paths and different tags, which is what we need.
      * `path_to_logs_dest` is where the log collection will end up after unarchiving and positioning the logs. These do not need to be unique either.
      * `tags` is for separating these logs from other logs, so they are searchable in Kibana. 
      * `log_regex` is the regex that filebeat.yml will use to find htese logs after they are placed by the ingest_tarball.py script. Will include the `path_to_logs_dest` but the regex should include all files you are copying in and exclude files you don't want filebeat to ingest. Files that match will be assigned the `tags` in Kibana. Should be unique as well.
      * if any of the defaults (see 'filebeat_input_template') need to be overwritten, add a key "custom_overwrites" (see `linux.system` logs for example, which uses this).

4) If these are logs that have a pattern different from the other logs that we are ingesting into kibana, you will have to add the pattern into our `config-templates/filebeat.template.yml` file, under the field `processors`.
  - This file contains all dissect patterns.
  - You will probably want to add at least two patterns: 1. for the log pattern itself; 2. One for field: "log.file.path" so that these new logs' filepath gets into kibana correctly also
