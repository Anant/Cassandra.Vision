# Collect and Ingest Cassandra logs into Elasticsearch and Kibana

Cassandra Analyzer is a tool to collect log files and nodetool output from your Cassandra cluster into a tarball and ingest the logs so they can be visualized using our prebuilt Kibana dashboard. These python scripts also run commands from TableAnalyzer and NodeAnalyzer and includes the results in the tarball. After running this, you will be able to either view your logs in the Kibana dashboard, perform data model review using the formatted spreadsheet generated by TableAnalyzer, or take the tarball that was collected and run other types of analytics.

There are three steps to this process, some of which you might be able to skip depending on what you already have setup: 
1) [Installing Elasticsearch, Filebeat, and Kibana](#Installing-Elasticsearch-Filebeat-and-Kibana)
2) [Collect Logs and Nodetool Output From Your Cluster](Collect-Logs-and-Nodetool-Output-From-Your-Cluster)
3) [Visualize Your Logs and Metrics](#Visualize-Your-Logs-and-Metrics)

Follow the instructions below to get started.

## Installing Elasticsearch, Filebeat, and Kibana
If you don't yet have Elasticsearch, Filebeat, and Kibana installed, there are different installation options you can use. 

1) **Ansible:** We have included a playbook and instructions in Cassandra.vision for you to use. [Get started here](../elastic-kibana-ansible/README.md)
2) **Manual Installation:** Of course you can always just install the tools yourself. You will need these three tools:
- [Elasticsearch](https://www.elastic.co/elasticsearch/)
- [Filebeat](https://www.elastic.co/beats/filebeat)
- [Kibana](https://www.elastic.co/kibana)

They can all be installed on the same node or they can be installed on different nodes. The only difference will be making sure you specify the right ip addresses when running the tool, as described in the following instructions. 

## Collect Logs and Nodetool Output From Your Cluster

See [`offline-log-collector`](./offline-log-collector/README.md) for collecting logs from your Cassandra cluster. 

### Already have a Datastax Opscenter Diagnostic Tarball?
Note that `offline-log-collector` can be skipped if you already have a Datastax Opscenter Diagnostic Tarball. While the Opscenter Diagnostic Tarball won't include the TableAnalyzer and NodeAnalyzer commands that we run using `offline-log-collector`, you can continue to the next step and ingest the diagnostic tarball into Elasticsearch and Kibana without any problem.

## Visualize Your Logs and Metrics 
If you finished collecting logs using [`offline-log-collector`](./offline-log-collector/README.md), or if you already have a Datastax Opscenter Diagnostic Tarball, you are now ready to begin performing your analysis. 

### Ingest Into Elasticsearch and Kibana
See directory [`./offline-log-ingester`](./offline-log-ingester/README.md) for ingesting logs into Elasticsearch and Kibana.

### Visualize Nodetool Metrics in a Formatted Spreadsheet
If you ran [`offline-log-collector`](./offline-log-collector/README.md) already, you can [click here to start transforming your nodetool output into a formatted spreadsheet using TableAnalyzer](./TableAnalyzer/README.md#generate-spreadsheet). Note that at this point, we have already ran the `cfstats.receive.py` script for you. Now all you will have to do is transform it into a CSV and then convert that into a spreadsheet, following instructions in the link above.

Alternatively, you can also just run TableAnalyzer's `cfstats.receive.py` script yourself which will accomplish the same thing. [Click here if you want to go down that route instead](./TableAnalyzer/README.md).